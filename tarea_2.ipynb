{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2\n",
    "Estudiantes:\n",
    "- Matías Fuentes\n",
    "- Larry Uribne"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de librerías e inicialización de sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/21 13:16:49 WARN Utils: Your hostname, Matiass-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.100.162 instead (on interface en0)\n",
      "23/06/21 13:16:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/21 13:16:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [1, 2, 3, 4]\n",
    "edges = [(1, 2), (2, 3), (2, 4), (3, 2)]\n",
    "rdd_nodes = sc.parallelize(nodes)\n",
    "rdd_edges = sc.parallelize(edges)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepara un RDD que tenga cada nodo con su Page Rank inicial. Luego, haz una función que prepare el\n",
    "mensaje que cada nodo va a enviar. Probablemente quieras almacenar estos valores como otro RDD."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparemos un RDD que contenga a cada nodo con su Page Rank inicial. El Page Rank inicial está dado por $\\frac{1}{N_{nodos}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.25), (2, 0.25), (3, 0.25), (4, 0.25)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_nodes = rdd_nodes.count()\n",
    "# Disponibilizamos la cantidad de nodos para todos los workers\n",
    "bc_n_nodes = sc.broadcast(n_nodes)\n",
    "\n",
    "rdd_ini = rdd_nodes.map(lambda x: (x, 1/bc_n_nodes.value))\n",
    "rdd_ini.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el paso siguiente necesitaremos la cantidad de vecinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {1: 1, 2: 2, 3: 1})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_counts = rdd_edges.countByKey()\n",
    "# Disponibilizamos la cantidad de mensajes enviados por nodo para todos los workers\n",
    "bc_neigh_counts = sc.broadcast(neigh_counts) \n",
    "bc_neigh_counts.value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mensaje saliente de cada nodo será el mensaje inicial dividido por la cantidad de vecinos. Vemos que solo el nodo 2 tiene más de 1 vecino, por tanto el único mensaje que será modificado es el suyo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.25), (2, 0.125), (3, 0.25), (4, 0.25)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_node_msg(node, init_msg):\n",
    "    if neigh_counts[node] != 0:\n",
    "        message = init_msg / bc_neigh_counts.value[node]\n",
    "        return message\n",
    "    return init_msg\n",
    "\n",
    "def preprare_rdd_msg(rdd_ini):\n",
    "    rdd_prep_msg = rdd_ini.map(lambda x: (x[0], prepare_node_msg(x[0], x[1])))\n",
    "    return rdd_prep_msg\n",
    "\n",
    "rdd_prep_msg = preprare_rdd_msg(rdd_ini)\n",
    "rdd_prep_msg.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Función que envía los mensajes a los nodos correspondientes y se hace cargo del merge de los mensajes recibidos por cada nodo. Debe retornar un RDD que para cada nodo diga cuál es el mensaje final recibido."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Priemro hacemos un join. Las llaves son los nodos emisores, y os valores resultantes seran tuplas donde el primer elemento es el nodo receptor y el segundo elemento es el mensaje recibido.\n",
    "\n",
    "Luego, generamos otro RDD que contenga solo los valores de la operación anterior y aplicamos reduceByKey para sumar los mensajes, obteniendo así tuplas donde la llave es el nodo receptor y el valor es la suma de todos los mensajes recibidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.5), (3, 0.125), (4, 0.125)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def send_msg(rdd_edges, rdd_prep_msg):\n",
    "    rdd_msg_sent = rdd_edges.join(rdd_prep_msg)\n",
    "    rdd_received_msg = rdd_msg_sent.values().reduceByKey(lambda x, y: x + y)\n",
    "    return rdd_received_msg\n",
    "rdd_received_msg = send_msg(rdd_edges, rdd_prep_msg)\n",
    "rdd_received_msg.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Haz una función que actualice el valor de Page Rank para cada nodo considerando el damping factor.\n",
    "Probablemente quieras hacer una función que tome el output del punto anterior y lo procese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.4625), (3, 0.14375), (4, 0.14375)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Disponibilizamos el damping factor para todos los workers\n",
    "damping = 0.85\n",
    "bc_damping = sc.broadcast(damping)\n",
    "def update_pr(rdd_received_msg):\n",
    "    rdd_updated_pr = rdd_received_msg.mapValues(lambda x: x * bc_damping.value + (1-bc_damping.value)/bc_n_nodes.value)\n",
    "    return rdd_updated_pr\n",
    "rdd_updated_pr = update_pr(rdd_received_msg)\n",
    "rdd_updated_pr.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Itera los pasos correspondientes por un número máximo de iteraciones, o hasta que la diferencia entre dos iteraciones del valor de Page Rank sea mínima."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar la legibilidad, consolidemos el proceso completo en una función. Usaremos el error absoluto medio como criterio de parada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(rdd1, rdd2):\n",
    "    abs_difference = rdd1.join(rdd2).values().map(lambda x: abs(x[0] - x[1]))\n",
    "    mean_abs_difference = abs_difference.reduce(lambda x, y: x + y)/2\n",
    "    return mean_abs_difference\n",
    "\n",
    "def page_rank(rdd_nodes, rdd_edges, damping=0.85, max_iterations = 10, eps=0.05):\n",
    "    n_nodes = rdd_nodes.count()\n",
    "    # Disponibilizamos la cantidad de nodos para todos los workers\n",
    "    bc_n_nodes = sc.broadcast(n_nodes)\n",
    "    neigh_counts = rdd_edges.countByKey()\n",
    "    # Disponibilizamos la cantidad de mensajes enviados por nodo para todos los workers\n",
    "    bc_neigh_counts = sc.broadcast(neigh_counts) \n",
    "    bc_neigh_counts.value\n",
    "    # Disponibilizamos el damping factor para todos los workers\n",
    "    bc_damping = sc.broadcast(damping)\n",
    "    # PageRank inicial\n",
    "    rdd_ini = rdd_nodes.map(lambda x: (x, 1/bc_n_nodes.value))\n",
    "    prev_pr = rdd_ini\n",
    "    # Preparar mensaje inicial\n",
    "    rdd_prep_msg = preprare_rdd_msg(rdd_ini)\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        # Enviar mensaje y gestionar merge al recibir\n",
    "        rdd_received_msg = send_msg(rdd_edges, rdd_prep_msg)\n",
    "        # Actualizar PageRank\n",
    "        rdd_updated_pr = update_pr(rdd_received_msg)\n",
    "        # Calcular distancia entre el PageRank recién obtenido y el de la iter previa\n",
    "        mean_distance = mean_absolute_error(prev_pr, rdd_updated_pr)\n",
    "        # Condición de parada\n",
    "        if mean_distance < eps:\n",
    "            break\n",
    "        # Mensaje enviado para iteración siguiente\n",
    "        rdd_prep_msg = preprare_rdd_msg(rdd_updated_pr)\n",
    "        # El PageRank de ahora es el PageRank previo en la próxima iteración\n",
    "        prev_pr = rdd_updated_pr\n",
    "        \n",
    "    print(f'Total iterations: {i}')\n",
    "    return rdd_updated_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 704:============================>                          (29 + 8) / 56]\r"
     ]
    }
   ],
   "source": [
    "final_pr = page_rank(rdd_nodes, rdd_edges)\n",
    "final_pr.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tareas_proce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

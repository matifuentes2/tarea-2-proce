{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2\n",
    "Estudiantes:\n",
    "- Matías Fuentes\n",
    "- Larry Uribne"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de librerías e inicialización de sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/21 13:16:49 WARN Utils: Your hostname, Matiass-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.100.162 instead (on interface en0)\n",
      "23/06/21 13:16:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/21 13:16:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import math\n",
    "spark = SparkSession.builder \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [1, 2, 3, 4]\n",
    "edges = [(1, 2), (2, 3), (2, 4), (3, 2)]\n",
    "rdd_nodes = sc.parallelize(nodes)\n",
    "rdd_edges = sc.parallelize(edges)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepara un RDD que tenga cada nodo con su Page Rank inicial. Luego, haz una función que prepare el\n",
    "mensaje que cada nodo va a enviar. Probablemente quieras almacenar estos valores como otro RDD."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparemos un RDD que contenga a cada nodo con su Page Rank inicial. El Page Rank inicial está dado por $\\frac{1}{N_{nodos}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.25), (2, 0.25), (3, 0.25), (4, 0.25)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_nodes = rdd_nodes.count()\n",
    "# Disponibilizamos la cantidad de nodos para todos los workers\n",
    "bc_n_nodes = sc.broadcast(n_nodes)\n",
    "\n",
    "rdd_ini = rdd_nodes.map(lambda x: (x, 1/bc_n_nodes.value))\n",
    "rdd_ini.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el paso siguiente necesitaremos la cantidad de vecinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {1: 1, 2: 2, 3: 1})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_counts = rdd_edges.countByKey()\n",
    "# Disponibilizamos la cantidad de mensajes enviados por nodo para todos los workers\n",
    "bc_neigh_counts = sc.broadcast(neigh_counts) \n",
    "bc_neigh_counts.value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mensaje saliente de cada nodo será el mensaje inicial dividido por la cantidad de vecinos. Vemos que solo el nodo 2 tiene más de 1 vecino, por tanto el único mensaje que será modificado es el suyo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.25), (2, 0.125), (3, 0.25), (4, 0.25)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_node_msg(node, init_msg):\n",
    "    if neigh_counts[node] != 0:\n",
    "        message = init_msg / bc_neigh_counts.value[node]\n",
    "        return message\n",
    "    return init_msg\n",
    "\n",
    "def preprare_rdd_msg(rdd_ini):\n",
    "    rdd_prep_msg = rdd_ini.map(lambda x: (x[0], prepare_node_msg(x[0], x[1])))\n",
    "    return rdd_prep_msg\n",
    "\n",
    "rdd_prep_msg = preprare_rdd_msg(rdd_ini)\n",
    "rdd_prep_msg.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Función que envía los mensajes a los nodos correspondientes y se hace cargo del merge de los mensajes recibidos por cada nodo. Debe retornar un RDD que para cada nodo diga cuál es el mensaje final recibido."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Priemro hacemos un join. Las llaves son los nodos emisores, y os valores resultantes seran tuplas donde el primer elemento es el nodo receptor y el segundo elemento es el mensaje recibido.\n",
    "\n",
    "Luego, generamos otro RDD que contenga solo los valores de la operación anterior y aplicamos reduceByKey para sumar los mensajes, obteniendo así tuplas donde la llave es el nodo receptor y el valor es la suma de todos los mensajes recibidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.5), (3, 0.125), (4, 0.125)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def send_msg(rdd_edges, rdd_prep_msg):\n",
    "    rdd_msg_sent = rdd_edges.join(rdd_prep_msg)\n",
    "    rdd_received_msg = rdd_msg_sent.values().reduceByKey(lambda x, y: x + y)\n",
    "    return rdd_received_msg\n",
    "rdd_received_msg = send_msg(rdd_edges, rdd_prep_msg)\n",
    "rdd_received_msg.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Haz una función que actualice el valor de Page Rank para cada nodo considerando el damping factor.\n",
    "Probablemente quieras hacer una función que tome el output del punto anterior y lo procese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.4625), (3, 0.14375), (4, 0.14375)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Disponibilizamos el damping factor para todos los workers\n",
    "damping = 0.85\n",
    "bc_damping = sc.broadcast(damping)\n",
    "def update_pr(rdd_received_msg):\n",
    "    rdd_updated_pr = rdd_received_msg.mapValues(lambda x: x * bc_damping.value + (1-bc_damping.value)/bc_n_nodes.value)\n",
    "    return rdd_updated_pr\n",
    "rdd_updated_pr = update_pr(rdd_received_msg)\n",
    "rdd_updated_pr.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Itera los pasos correspondientes por un número máximo de iteraciones, o hasta que la diferencia entre dos iteraciones del valor de Page Rank sea mínima."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar la legibilidad, consolidemos el proceso completo en una función. Usaremos el error absoluto medio como criterio de parada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(rdd1, rdd2):\n",
    "    abs_difference = rdd1.join(rdd2).values().map(lambda x: abs(x[0] - x[1]))\n",
    "    mean_abs_difference = abs_difference.reduce(lambda x, y: x + y)/2\n",
    "    return mean_abs_difference\n",
    "\n",
    "def page_rank(rdd_nodes, rdd_edges, damping=0.85, max_iterations = 10, eps=0.05):\n",
    "    n_nodes = rdd_nodes.count()\n",
    "    # Disponibilizamos la cantidad de nodos para todos los workers\n",
    "    bc_n_nodes = sc.broadcast(n_nodes)\n",
    "    neigh_counts = rdd_edges.countByKey()\n",
    "    # Disponibilizamos la cantidad de mensajes enviados por nodo para todos los workers\n",
    "    bc_neigh_counts = sc.broadcast(neigh_counts) \n",
    "    bc_neigh_counts.value\n",
    "    # Disponibilizamos el damping factor para todos los workers\n",
    "    bc_damping = sc.broadcast(damping)\n",
    "    # PageRank inicial\n",
    "    rdd_ini = rdd_nodes.map(lambda x: (x, 1/bc_n_nodes.value))\n",
    "    prev_pr = rdd_ini\n",
    "    # Preparar mensaje inicial\n",
    "    rdd_prep_msg = preprare_rdd_msg(rdd_ini)\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        # Enviar mensaje y gestionar merge al recibir\n",
    "        rdd_received_msg = send_msg(rdd_edges, rdd_prep_msg)\n",
    "        # Actualizar PageRank\n",
    "        rdd_updated_pr = update_pr(rdd_received_msg)\n",
    "        # Calcular distancia entre el PageRank recién obtenido y el de la iter previa\n",
    "        mean_distance = mean_absolute_error(prev_pr, rdd_updated_pr)\n",
    "        # Condición de parada\n",
    "        if mean_distance < eps:\n",
    "            break\n",
    "        # Mensaje enviado para iteración siguiente\n",
    "        rdd_prep_msg = preprare_rdd_msg(rdd_updated_pr)\n",
    "        # El PageRank de ahora es el PageRank previo en la próxima iteración\n",
    "        prev_pr = rdd_updated_pr\n",
    "        \n",
    "    print(f'Total iterations: {i}')\n",
    "    return rdd_updated_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iterations: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2, 0.11527618701171877), (3, 0.10328731884765627), (4, 0.10328731884765627)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pr = page_rank(rdd_nodes, rdd_edges)\n",
    "final_pr.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generando grafos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_graph(n_nodes, n_edges, tier_dict):\n",
    "#     nodes = list(range(1, n_nodes+1))\n",
    "#     uniform_prob = 1/n_nodes\n",
    "#     probabilities = [0.2, 0.5, 0.3]\n",
    "#     np.random.choice(elements, 10, p=probabilities)\n",
    "#     return nodes\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recibir input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo tomado de https://www.geeksforgeeks.org/dijkstras-shortest-path-algorithm-greedy-algo-7/\n",
    "nodes = list(range(1, 9))\n",
    "edges = [(1,2,4), (1,3,2), (1,4,1), (3,2,1), (3,5,6),(4,5,9),(4,6,2),(7,8,9), (5,6,1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_node = 1\n",
    "bc_initial_node = sc.broadcast(initial_node) # Disponibilizar para todos los worker\n",
    "rdd_nodes = sc.parallelize(nodes)\n",
    "rdd_edges = sc.parallelize(edges)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formateamos las aristas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, (2, 4)),\n",
       " (1, (3, 2)),\n",
       " (1, (4, 1)),\n",
       " (3, (2, 1)),\n",
       " (3, (5, 6)),\n",
       " (4, (5, 9)),\n",
       " (4, (6, 2)),\n",
       " (7, (8, 9)),\n",
       " (5, (6, 1))]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_edges = rdd_edges.map(lambda x: (x[0], (x[1], x[2])))\n",
    "rdd_edges.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Escoge el nodo inicial, este nodo tiene costo acumulado 0 y todos los demás tienen costo acumulado\n",
    "infinito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0), (2, inf), (3, inf), (4, inf), (5, inf), (6, inf), (7, inf), (8, inf)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_init = rdd_nodes.map(lambda x: (x, math.inf) if x != bc_initial_node.value else (x, 0))\n",
    "rdd_init.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. En cada iteración, cada nodo comunica el costo acumulado a sus vecinos. Cada nodo recibe este costo,\n",
    "sumado con el costo de atravesar la arista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, ((2, 4), 0)),\n",
       " (1, ((3, 2), 0)),\n",
       " (1, ((4, 1), 0)),\n",
       " (3, ((2, 1), inf)),\n",
       " (3, ((5, 6), inf)),\n",
       " (4, ((5, 9), inf)),\n",
       " (4, ((6, 2), inf)),\n",
       " (5, ((6, 1), inf)),\n",
       " (7, ((8, 9), inf))]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_edges.join(rdd_init).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 4),\n",
       " (3, 2),\n",
       " (4, 1),\n",
       " (2, inf),\n",
       " (5, inf),\n",
       " (5, inf),\n",
       " (6, inf),\n",
       " (6, inf),\n",
       " (8, inf)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_pass_msg = rdd_edges.join(rdd_init).mapValues(lambda x: (x[0][0], x[0][1] + x[1])).values()\n",
    "rdd_pass_msg.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Para hacer merge de todos los mensajes dejamos el mínimo de todos los costos. Así, actualizamos cada\n",
    "nodo con el costo mínimo recibido solo si es menor al costo acumulado que ya tenía ese nodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 4), (3, 2), (4, 1), (5, inf), (6, inf), (8, inf)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_reduce_msg = rdd_pass_msg.reduceByKey(lambda x, y: min(x, y))\n",
    "rdd_reduce_msg.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 0), (2, 4), (3, 2), (4, 1), (5, inf), (6, inf), (7, inf), (8, inf)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def robust_min(x):\n",
    "    a, b = x\n",
    "    try:\n",
    "        return min(a,b)\n",
    "    except:\n",
    "        return a if a != None else b\n",
    "    \n",
    "rdd_updated_cost = rdd_init.leftOuterJoin(rdd_reduce_msg).mapValues(lambda x: robust_min(x))\n",
    "rdd_updated_cost.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Si en dos iteraciones el costo en llegar para cada nodo no cambia, entonces nos detenemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_condition(rdd_pre, rdd_post):\n",
    "    # RDD donde las llaves son los nodos y los valores son 1 si no hubo cambio y 0 si lo hubo\n",
    "    rdd_track_changes = rdd_pre.join(rdd_post).mapValues(lambda x: int(x[0] == x[1]))\n",
    "    # Intersección\n",
    "    n_changes = rdd_track_changes.values().reduce(lambda x, y: x + y) \n",
    "    return n_changes == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_condition(rdd_init, rdd_updated_cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tareas_proce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

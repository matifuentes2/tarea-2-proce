{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problema 1\n",
    "Estudiantes:\n",
    "- Matías Fuentes\n",
    "- Larry Uribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/matif/.pyenv/versions/3.10.0/envs/tareas_proce/lib/python3.10/site-packages (3.4.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /Users/matif/.pyenv/versions/3.10.0/envs/tareas_proce/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-06-27 18:57:21--  https://github.com/IIC2440/Syllabus-2023-1/raw/main/Actividades/cora.zip\n",
      "Resolving github.com (github.com)... 20.201.28.151\n",
      "Connecting to github.com (github.com)|20.201.28.151|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/IIC2440/Syllabus-2023-1/main/Actividades/cora.zip [following]\n",
      "--2023-06-27 18:57:22--  https://raw.githubusercontent.com/IIC2440/Syllabus-2023-1/main/Actividades/cora.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8003::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 165770 (162K) [application/zip]\n",
      "Saving to: ‘cora.zip.2’\n",
      "\n",
      "cora.zip.2          100%[===================>] 161.88K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2023-06-27 18:57:22 (12.3 MB/s) - ‘cora.zip.2’ saved [165770/165770]\n",
      "\n",
      "unzip:  cannot find or open /content/cora.zip, /content/cora.zip.zip or /content/cora.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/IIC2440/Syllabus-2023-1/raw/main/Actividades/cora.zip\n",
    "!unzip /content/cora.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import math\n",
    "spark = SparkSession.builder \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [1, 2, 3, 4]\n",
    "edges = [(1, 2), (2, 3), (2, 4), (3, 2)]\n",
    "rdd_nodes = sc.parallelize(nodes)\n",
    "rdd_edges = sc.parallelize(edges)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepara un RDD que tenga cada nodo con su Page Rank inicial. Luego, haz una función que prepare el\n",
    "mensaje que cada nodo va a enviar. Probablemente quieras almacenar estos valores como otro RDD."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparemos un RDD que contenga a cada nodo con su Page Rank inicial. El Page Rank inicial está dado por $\\frac{1}{N_{nodos}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.25), (2, 0.25), (3, 0.25), (4, 0.25)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_nodes = rdd_nodes.count()\n",
    "# Disponibilizamos la cantidad de nodos para todos los workers\n",
    "bc_n_nodes = sc.broadcast(n_nodes)\n",
    "\n",
    "rdd_ini = rdd_nodes.map(lambda x: (x, 1/bc_n_nodes.value))\n",
    "rdd_ini.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el paso siguiente necesitaremos la cantidad de vecinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {1: 1, 2: 2, 3: 1})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_counts = rdd_edges.countByKey()\n",
    "# Disponibilizamos la cantidad de mensajes enviados por nodo para todos los workers\n",
    "bc_neigh_counts = sc.broadcast(neigh_counts) \n",
    "bc_neigh_counts.value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mensaje saliente de cada nodo será el mensaje inicial dividido por la cantidad de vecinos. Vemos que solo el nodo 2 tiene más de 1 vecino, por tanto el único mensaje que será modificado es el suyo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.25), (2, 0.125), (3, 0.25), (4, 0.25)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_node_msg(node, init_msg):\n",
    "    if neigh_counts[node] != 0:\n",
    "        message = init_msg / bc_neigh_counts.value[node]\n",
    "        return message\n",
    "    return init_msg\n",
    "\n",
    "def preprare_rdd_msg(rdd_ini):\n",
    "    rdd_prep_msg = rdd_ini.map(lambda x: (x[0], prepare_node_msg(x[0], x[1])))\n",
    "    return rdd_prep_msg\n",
    "\n",
    "rdd_prep_msg = preprare_rdd_msg(rdd_ini)\n",
    "rdd_prep_msg.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Función que envía los mensajes a los nodos correspondientes y se hace cargo del merge de los mensajes recibidos por cada nodo. Debe retornar un RDD que para cada nodo diga cuál es el mensaje final recibido."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero hacemos un join. Las llaves son los nodos emisores, y los valores resultantes serán tuplas donde el primer elemento es el nodo receptor y el segundo elemento es el mensaje recibido.\n",
    "\n",
    "Luego, generamos otro RDD que contenga solo los valores de la operación anterior y aplicamos reduceByKey para sumar los mensajes, obteniendo así tuplas donde la llave es el nodo receptor y el valor es la suma de todos los mensajes recibidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.5), (3, 0.125), (4, 0.125)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def send_msg(rdd_edges, rdd_prep_msg):\n",
    "    rdd_received_msg = rdd_edges.join(rdd_prep_msg)\n",
    "    rdd_reduced_msg = rdd_received_msg.values().reduceByKey(lambda x, y: x + y)\n",
    "    return rdd_reduced_msg\n",
    "rdd_reduced_msg = send_msg(rdd_edges, rdd_prep_msg)\n",
    "rdd_reduced_msg.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Haz una función que actualice el valor de Page Rank para cada nodo considerando el damping factor.\n",
    "Probablemente quieras hacer una función que tome el output del punto anterior y lo procese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.4625), (3, 0.14375), (4, 0.14375)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Disponibilizamos el damping factor para todos los workers\n",
    "damping = 0.85\n",
    "bc_damping = sc.broadcast(damping)\n",
    "def update_pr(rdd_reduced_msg):\n",
    "    rdd_updated_pr = rdd_reduced_msg.mapValues(lambda x: x * bc_damping.value + (1-bc_damping.value)/bc_n_nodes.value)\n",
    "    return rdd_updated_pr\n",
    "rdd_updated_pr = update_pr(rdd_reduced_msg)\n",
    "rdd_updated_pr.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Itera los pasos correspondientes por un número máximo de iteraciones, o hasta que la diferencia entre dos iteraciones del valor de Page Rank sea mínima."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar la legibilidad, consolidemos el proceso completo en una función. Usaremos el error absoluto medio como criterio de parada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(rdd1, rdd2):\n",
    "    abs_difference = rdd1.join(rdd2).values().map(lambda x: abs(x[0] - x[1]))\n",
    "    mean_abs_difference = abs_difference.reduce(lambda x, y: x + y)/2\n",
    "    return mean_abs_difference\n",
    "\n",
    "def page_rank(rdd_nodes, rdd_edges, damping=0.85, max_iterations = 1000, eps=0.05):\n",
    "    n_nodes = rdd_nodes.count()\n",
    "    # Disponibilizamos la cantidad de nodos para todos los workers\n",
    "    bc_n_nodes = sc.broadcast(n_nodes)\n",
    "    neigh_counts = rdd_edges.countByKey()\n",
    "    # Disponibilizamos la cantidad de mensajes enviados por nodo para todos los workers\n",
    "    bc_neigh_counts = sc.broadcast(neigh_counts) \n",
    "    bc_neigh_counts.value\n",
    "    # Disponibilizamos el damping factor para todos los workers\n",
    "    bc_damping = sc.broadcast(damping)\n",
    "    # PageRank inicial\n",
    "    rdd_ini = rdd_nodes.map(lambda x: (x, 1/bc_n_nodes.value))\n",
    "    prev_pr = rdd_ini\n",
    "    # Preparar mensaje inicial\n",
    "    rdd_prep_msg = preprare_rdd_msg(rdd_ini)\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        # Enviar mensaje y gestionar merge al recibir\n",
    "        rdd_reduced_msg = send_msg(rdd_edges, rdd_prep_msg)\n",
    "        # Actualizar PageRank\n",
    "        rdd_updated_pr = update_pr(rdd_reduced_msg)\n",
    "        # Calcular distancia entre el PageRank recién obtenido y el de la iter previa\n",
    "        mean_distance = mean_absolute_error(prev_pr, rdd_updated_pr)\n",
    "        # Condición de parada\n",
    "        if mean_distance < eps:\n",
    "            break\n",
    "        # Mensaje enviado para iteración siguiente\n",
    "        rdd_prep_msg = preprare_rdd_msg(rdd_updated_pr)\n",
    "        # El PageRank de ahora es el PageRank previo en la próxima iteración\n",
    "        prev_pr = rdd_updated_pr\n",
    "        \n",
    "    print(f'Total iterations: {i+1}')\n",
    "    return rdd_updated_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iterations: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2, 0.11527618701171877), (3, 0.10328731884765627), (4, 0.10328731884765627)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pr = page_rank(rdd_nodes, rdd_edges)\n",
    "final_pr.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sólo se devuelven los nodos con un PageRank distinto de cero."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba con grafo Cora\n",
    "\n",
    "Se deja el código dispuesto para hacer pruebas con este grafo, pero es muy grande y la verdad es que no llega a converger en un tiempo razonable coriéndolo con 1 máquina."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# citas = pd.read_csv('cora/cora.cites',sep=\"\\t\",\n",
    "#                     header=None,\n",
    "#                     names=[\"target\", \"source\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraer nodos y conexiones, y cargarlos a sus respectivos RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes = list(set(list(citas.target.values) + list(citas.source.values)))\n",
    "# edges = []\n",
    "# for source, target in citas.values:\n",
    "#     edges.append((source, target))\n",
    "# rdd_nodes = sc.parallelize(nodes)\n",
    "# rdd_edges = sc.parallelize(edges)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correr PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdd_result = page_rank(rdd_nodes, rdd_edges)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sólo se devuelven los nodos con un PageRank distinto de cero."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tareas_proce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

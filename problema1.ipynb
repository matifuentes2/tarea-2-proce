{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problema 1\n",
    "Estudiantes:\n",
    "- Matías Fuentes\n",
    "- Larry Uribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import math\n",
    "spark = SparkSession.builder \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [1, 2, 3, 4]\n",
    "edges = [(1, 2), (2, 3), (2, 4), (3, 2)]\n",
    "rdd_nodes = sc.parallelize(nodes)\n",
    "rdd_edges = sc.parallelize(edges)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepara un RDD que tenga cada nodo con su Page Rank inicial. Luego, haz una función que prepare el\n",
    "mensaje que cada nodo va a enviar. Probablemente quieras almacenar estos valores como otro RDD."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparemos un RDD que contenga a cada nodo con su Page Rank inicial. El Page Rank inicial está dado por $\\frac{1}{N_{nodos}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = rdd_nodes.count()\n",
    "# Disponibilizamos la cantidad de nodos para todos los workers\n",
    "bc_n_nodes = sc.broadcast(n_nodes)\n",
    "\n",
    "rdd_ini = rdd_nodes.map(lambda x: (x, 1/bc_n_nodes.value))\n",
    "rdd_ini.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el paso siguiente necesitaremos la cantidad de vecinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_counts = rdd_edges.countByKey()\n",
    "# Disponibilizamos la cantidad de mensajes enviados por nodo para todos los workers\n",
    "bc_neigh_counts = sc.broadcast(neigh_counts) \n",
    "bc_neigh_counts.value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mensaje saliente de cada nodo será el mensaje inicial dividido por la cantidad de vecinos. Vemos que solo el nodo 2 tiene más de 1 vecino, por tanto el único mensaje que será modificado es el suyo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_node_msg(node, init_msg):\n",
    "    if neigh_counts[node] != 0:\n",
    "        message = init_msg / bc_neigh_counts.value[node]\n",
    "        return message\n",
    "    return init_msg\n",
    "\n",
    "def preprare_rdd_msg(rdd_ini):\n",
    "    rdd_prep_msg = rdd_ini.map(lambda x: (x[0], prepare_node_msg(x[0], x[1])))\n",
    "    return rdd_prep_msg\n",
    "\n",
    "rdd_prep_msg = preprare_rdd_msg(rdd_ini)\n",
    "rdd_prep_msg.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Función que envía los mensajes a los nodos correspondientes y se hace cargo del merge de los mensajes recibidos por cada nodo. Debe retornar un RDD que para cada nodo diga cuál es el mensaje final recibido."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero hacemos un join. Las llaves son los nodos emisores, y los valores resultantes serán tuplas donde el primer elemento es el nodo receptor y el segundo elemento es el mensaje recibido.\n",
    "\n",
    "Luego, generamos otro RDD que contenga solo los valores de la operación anterior y aplicamos reduceByKey para sumar los mensajes, obteniendo así tuplas donde la llave es el nodo receptor y el valor es la suma de todos los mensajes recibidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_msg(rdd_edges, rdd_prep_msg):\n",
    "    rdd_msg_sent = rdd_edges.join(rdd_prep_msg)\n",
    "    rdd_received_msg = rdd_msg_sent.values().reduceByKey(lambda x, y: x + y)\n",
    "    return rdd_received_msg\n",
    "rdd_received_msg = send_msg(rdd_edges, rdd_prep_msg)\n",
    "rdd_received_msg.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Haz una función que actualice el valor de Page Rank para cada nodo considerando el damping factor.\n",
    "Probablemente quieras hacer una función que tome el output del punto anterior y lo procese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disponibilizamos el damping factor para todos los workers\n",
    "damping = 0.85\n",
    "bc_damping = sc.broadcast(damping)\n",
    "def update_pr(rdd_received_msg):\n",
    "    rdd_updated_pr = rdd_received_msg.mapValues(lambda x: x * bc_damping.value + (1-bc_damping.value)/bc_n_nodes.value)\n",
    "    return rdd_updated_pr\n",
    "rdd_updated_pr = update_pr(rdd_received_msg)\n",
    "rdd_updated_pr.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Itera los pasos correspondientes por un número máximo de iteraciones, o hasta que la diferencia entre dos iteraciones del valor de Page Rank sea mínima."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar la legibilidad, consolidemos el proceso completo en una función. Usaremos el error absoluto medio como criterio de parada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(rdd1, rdd2):\n",
    "    abs_difference = rdd1.join(rdd2).values().map(lambda x: abs(x[0] - x[1]))\n",
    "    mean_abs_difference = abs_difference.reduce(lambda x, y: x + y)/2\n",
    "    return mean_abs_difference\n",
    "\n",
    "def page_rank(rdd_nodes, rdd_edges, damping=0.85, max_iterations = 1000, eps=0.05):\n",
    "    n_nodes = rdd_nodes.count()\n",
    "    # Disponibilizamos la cantidad de nodos para todos los workers\n",
    "    bc_n_nodes = sc.broadcast(n_nodes)\n",
    "    neigh_counts = rdd_edges.countByKey()\n",
    "    # Disponibilizamos la cantidad de mensajes enviados por nodo para todos los workers\n",
    "    bc_neigh_counts = sc.broadcast(neigh_counts) \n",
    "    bc_neigh_counts.value\n",
    "    # Disponibilizamos el damping factor para todos los workers\n",
    "    bc_damping = sc.broadcast(damping)\n",
    "    # PageRank inicial\n",
    "    rdd_ini = rdd_nodes.map(lambda x: (x, 1/bc_n_nodes.value))\n",
    "    prev_pr = rdd_ini\n",
    "    # Preparar mensaje inicial\n",
    "    rdd_prep_msg = preprare_rdd_msg(rdd_ini)\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        # Enviar mensaje y gestionar merge al recibir\n",
    "        rdd_received_msg = send_msg(rdd_edges, rdd_prep_msg)\n",
    "        # Actualizar PageRank\n",
    "        rdd_updated_pr = update_pr(rdd_received_msg)\n",
    "        # Calcular distancia entre el PageRank recién obtenido y el de la iter previa\n",
    "        mean_distance = mean_absolute_error(prev_pr, rdd_updated_pr)\n",
    "        # Condición de parada\n",
    "        if mean_distance < eps:\n",
    "            break\n",
    "        # Mensaje enviado para iteración siguiente\n",
    "        rdd_prep_msg = preprare_rdd_msg(rdd_updated_pr)\n",
    "        # El PageRank de ahora es el PageRank previo en la próxima iteración\n",
    "        prev_pr = rdd_updated_pr\n",
    "        \n",
    "    print(f'Total iterations: {i+1}')\n",
    "    return rdd_updated_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pr = page_rank(rdd_nodes, rdd_edges)\n",
    "final_pr.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba con grafo Cora"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citas = pd.read_csv('cora/cora.cites',sep=\"\\t\",\n",
    "                    header=None,\n",
    "                    names=[\"target\", \"source\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraer nodos y conexiones, y cargarlos a sus respectivos RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(set(list(citas.target.values) + list(citas.source.values)))\n",
    "edges = []\n",
    "for source, target in citas.values:\n",
    "    edges.append((source, target))\n",
    "rdd_nodes = sc.parallelize(nodes)\n",
    "rdd_edges = sc.parallelize(edges)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correr PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_result = page_rank(rdd_nodes, rdd_edges)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tareas_proce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
